<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: algorithmy | Need for Air]]></title>
  <link href="http://needforair.com/blog/categories/algorithmy/atom.xml" rel="self"/>
  <link href="http://needforair.com/"/>
  <updated>2013-03-14T15:17:11+01:00</updated>
  <id>http://needforair.com/</id>
  <author>
    <name><![CDATA[Need for Air]]></name>
    
  </author>
  <generator uri="http://ryandeussing.com/">Ryan Deussing</generator>

  
  <entry>
    <title type="html"><![CDATA[The Game of Go: a Programmer's Perspective]]></title>
    <link href="http://needforair.com/blog/2012/04/18/game-of-go/"/>
    <updated>2012-04-18T08:30:00+02:00</updated>
    <id>http://needforair.com/blog/2012/04/18/game-of-go</id>
    <content type="html"><![CDATA[<blockquote class="tldr-embed-widget" data-align="center">      <p>      <a href="http://tldr.io/tldrs/513a39234cf688202900007c/the-game-of-go-a-programmers-perspective-need-for-air" class="link-to-tldr-page" target="_blank">Summary of "The Game of Go: a Programmer's Perspective - Need for Air"</a> (via <a href="http://tldr.io" target="_blank">tldr.io</a>)      <ul>        <li style="margin-bottom: 10px; line-height: 130%;">The Game of Go is very interesting from an AI point of view because computers are still very weak at it (unlike Chess where they compete with top humans).</li>        <li style="margin-bottom: 10px; line-height: 130%;">That's because there are a huge nimber of possible games, no good heuristic to evaluate a given position, and computers suck at pattern recognition.</li>        <li style="margin-bottom: 10px; line-height: 130%;">Amazingly, computers improved a lot by using random playouts to evaluate positions (play a lot of games at random from the position and see the success rate).</li>        <li style="margin-bottom: 10px; line-height: 130%;">They use multi-armed bandit algorithms to achieve the good tradeoff between exploitation (trying promising moves) and exploration (trying unknown moves).</li>        <li style="margin-bottom: 10px; line-height: 130%;">In addition, they use a little expert knowledge (not nearly as much as in Chess), parallelization and reinforcement learning.</li>      </ul>      </p></blockquote>


<script async src="http://needforair.com//tldr.io/embed/widget-embed.js" charset="utf-8"></script>


<p>The game of go is very interesting from an AI programmer's point of
view, because of how difficult it is to make a computer compete against
a strong human and how researchers approached the problem. Paradoxically, the use of randomly played games has helped computers get much stronger.</p>

<p><a href="http://www.flickr.com/photos/92544159@N00/322662164/"><img src="http://farm1.staticflickr.com/134/322662164_0260e91add_n.jpg" alt="Go" /></a>
<em>by <a href="http://www.flickr.com/photos/obli/" title="Author">oblivionz</a></em></p>

<h2>Game of Go: a (very) brief overview</h2>

<p>Go is wildly popular in Asia but little known in the Western world. Similar to Chess, it is a strategy game where two players take
turn placing stones on a board. The key differences between these
two are:</p>

<ul>
<li>In Go, the board starts empty, and you add stones at each turn whereas in
chess you start with an army and try to destroy the other one</li>
<li>The <a href="http://senseis.xmp.net/?RulesOfGoIntroductory">rules</a> are much simpler in Go than in Chess: in particular there is only one type of stone while Chess uses six different pieces</li>
</ul>


<p>I really encourage you to check it out, you can <a href="http://senseis.xmp.net/?RulesOfGoIntroductory">learn to play here</a> and <a href="http://www.gokgs.com/">play here</a>.</p>

<h2>Compexity, comparison to chess</h2>

<p>Even though the rules are simple, it has proven to be very hard to
build a good Go-playing program. In fact, while top Chess-playing
softwares can compete with the best humans (remember how Deep Blue beat
Gary Kasparov in 1997), even strong amateurs can beat the top Go-playing
programs. And strong amateurs are much weaker than top pros. There are three main reasons for this:</p>

<ul>
<li><strong>Game-tree complexity</strong>: there are about <a href="http://en.wikipedia.org/wiki/Shannon_number">10<sup>123</sup> possible games
in Chess</a>. As for Go,
<a href="http://en.wikipedia.org/wiki/Go_and_mathematics">estimates vary</a> but
the <a href="http://www.usgo.org/resources/topten.html">American Go Association reckons there are 10<sup>700</sup> possible
games</a>. This is because there
are more turns in a Go game than in a Chess game (200 vs 50 on average),
and more possibilities at each turn in Go (up to 350 vs 50).</li>
<li><strong><a href="http://en.wikipedia.org/wiki/Evaluation_function">Lack of a good heuristic</a></strong>: Chess programs are able to evaluate quite accurately and quickly whether a given position is better than another one. On the contrary, no good heuristic has been found for Go yet.</li>
<li><strong>Pattern-recognition</strong>: strong Go players rely heavily on recognizing
the shapes the stones take. There are too many of them for a computer
to try and recognize in a game timeframe, and <a href="http://curiosity.discovery.com/question/humans-better-than-computers">humans are much better than them at this</a>.</li>
</ul>


<h2>Key ideas behind current Go-playing programs</h2>

<p>This complexity is what makes the study of Go algorithms so interesting.
A few years ago we saw a spectacular improvement, led by a
program called <a href="http://www.lri.fr/~teytaud/mogo.html">MoGo</a>. The key
ideas behind MoGo are:</p>

<ul>
<li><strong>Position evaluation using random games</strong>: paradoxically, it was
found that the best way to evaluate a position is to play, from this
position, a lot of games were each player puts stones at random
on the board. A position's score is simply the percentage of won
random games.</li>
<li><strong>Use of <a href="http://en.wikipedia.org/wiki/Multi-armed_bandit">multi-armed bandit</a> algorithms</strong> to decrease the branching factor (the number of moves the program has to consider at each turn). The goal here is to optimize the trade-off between exploration (trying new moves) and exploitation (further testing the most promising moves to select the best one). The computer begins with a prior probability distribution for every possible move. It picks one according to this distribution, plays a random game from the corresponding position and uses the result to update the probability for this move. It then selects another possible move according to the updated distribution and so on.</li>
<li><strong>Use of a little expert knowledge</strong>: the prior distribution used in the
multi-armed bandit is calculated so as to avoid trivially stupid moves.
For the opening of the game, classic starting positions are also
favored. And the random games are not completely random since they avoid
certain moves according to simple patterns. Nonetheless, expert
knowledge is used scarcely as it really hurts the exploration part of
the algorithm.</li>
<li><strong>Parallelization</strong>: MoGo and the likes can become very good on
computer clusters, since the random game part can be run on mutliple
CPUs. The <a href="http://en.wikipedia.org/wiki/Amdahl's_law">speedup factor</a> is
about 8x.</li>
<li><strong>Reinforcement learning</strong>: MoGo learns during the game and the
randoms play-outs that some kind of responses to his opponent's moves are likely to have a bad
result, and assigns them a lower probability.</li>
</ul>


<p>You can learn more on MoGo <a href="http://www.pleinsud.u-psud.fr/specialR2008/en/12_GOthique.pdf">in this article</a>.</p>

<h2>Current strength of computers</h2>

<p>Today, Go-playing programs are able to compete with professional players on small (9x9) boards, and with strong amateurs (5d KGS) on normal boards (19x19). This is quite an achievement, but there is still a long way to go before they can face professional players on normal boards!</p>

<p><em>I am a Go player myself, even though not very good! During an
internship in a Computer Science laboratory, I worked on <a href="http://www.lri.fr/~teytaud/mogo.html">MoGo</a> for 2 months in 2008.</em><br/>
<em>Special thanks to <a href="http://www.linkedin.com/pub/arpad-rimmel/b/9a7/847">Arpad Rimmel</a> for having reviewed this article. He spent 3 years working on Mogo when he was a PhD student.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Role of Computers in Text Summarization]]></title>
    <link href="http://needforair.com/blog/2012/04/06/why-computers-are-bad-at-summarizing-text/"/>
    <updated>2012-04-06T08:30:00+02:00</updated>
    <id>http://needforair.com/blog/2012/04/06/why-computers-are-bad-at-summarizing-text</id>
    <content type="html"><![CDATA[<p>As Stanislas explained in <a href="http://needforair.com/blog/2012/03/09/how-to-keep-up-with-the-information-overload/" title="Information Overload">this previous post</a>, we believe we are dealing with too much information to keep up on the Internet. The natural solution is text summarization, and computers can help us there.</p>

<p><a href="http://www.flickr.com/photos/xeeliz/3558255554/sizes/l/in/photostream/"><img src="http://farm4.staticflickr.com/3376/3558255554_9f9c480132_n.jpg" alt="Summary" /></a>
<em>by <a href="http://www.flickr.com/photos/xeeliz/" title="Author">Xeeiliz</a></em></p>

<p>There are roughly two kinds of summaries: the ones that consist of a few of
the most important sentences extracted from the text, the keyphrases, and the ones that
are written from scratch without necessarily using the same phrasing, called abstract summaries.</p>

<h2>Finding the most relevant content: keyphrase extraction</h2>

<p>The big advantage of keyphrase-based summaries is that there is no risk
of miscomprehension since they are composed of unrephrased pieces of the
text. Moreover, computers are able to compute them and get decent
results. There are two main ways to do it: supervised and unsupervised
extraction.</p>

<h3>When you know the context: extraction as supervised learning</h3>

<p>One way to perform this task is described by Peter Turney in <a href="http://webdocs.cs.ualberta.ca/~lindek/650/papers/turney.pdf">this paper</a>. He found that using a custom-designed algorithm that incorporates specialized domain knowledge on a text generates yields very good results: 80% of keyphrases are deemed acceptable by human readers. The problem with this approach is that it requires the computer to know the topic beforehand. It is possible to use a prior first step to determine what it is, but this is difficult and the results are terrible if we get it wrong.</p>

<h3>Applicable to any text: unsupervised keyphrase extraction</h3>

<p>This approaches enables us to extract keyphrases from a text without any
prior knowledge, which is a tremendous improvement upon the previous method. There a several algorithms, and one notable current example is <a href="http://www.summly.com/">Summly</a>. I will explain one of those, named TextRank, to give you a feeling of the kind of techniques used in this field.</p>

<p>The TextRank algorithm was developped by Rada Mihalcea and Paul Tarau in
<a href="http://acl.ldc.upenn.edu/acl2004/emnlp/pdf/Mihalcea.pdf">this paper</a>. The key idea is that a text
unit (word or phrase depending on the need) that is close to a lot of other important text units is likely a keyphrase. Using the parallel between the "close to" relation and the "referred to by" relation of hyperlinks, TextRank uses Google's <a href="http://en.wikipedia.org/wiki/PageRank">PageRank</a> to determine which text units are the most important. It works well, its main author was even awarded a $100k grant by Google for her work on keyphrase extraction.</p>

<h2>The best: abstract summarization</h2>

<p>Even though they can be very useful, keyphrase-based summaries are still
rudimentary compared to abstract summaries, because they are much nicer
to read, and we are sure no important information was "left behind" (i.e a keyphrase was not extracted). Also, keyphrase extraction algorithms still find it hard to
summarize technical articles.</p>

<p>Abstract summarization is the limit of what computers can do today. The
main reason for this is that they struggle with the following tasks:</p>

<ul>
<li><strong>Coreferences understanding</strong>. For example, who does 'he'
references in the sentence 'Paul told John he should play squash'?</li>
<li><strong>Word sense disambiguation</strong>. In 'I need batteries for
my mouse', are we talking about the animal or the device?</li>
<li><strong>Sentiment analysis</strong>. Understanding the mood of the writer is often
key to understanding a text, all the more when there is sarcasm.</li>
</ul>


<h2>Can computers help humans summarize text?</h2>

<p>Today, computers are not good at summarizing text, and they probably
will be for a long time. Nevertheless, we may be able to make
significant progress if we had a huge database of summarize. That's what
we're working on, so future will tell!</p>

<p><em>Note: some examples were taken from <a href="https://class.coursera.org/nlp/">Stanford's Natural Language
Processing online class</a>. If you couldn't take
it this quarter, look for it, it is a terrific place to learn about this
topic</em></p>
]]></content>
  </entry>
  
</feed>
